# 공부


#### 프로그램과 프로세스

* 프로그램(Program): 하드디스크 등에 저장된 명령문의 집합체
* 프로세스(Process): 실행 중인 프로그램 (하드디스크에 있는 프로그램이 메모리에 올라가면 실행 중인 프로그램, 즉 프로세스가 된다!)


#### 프로세스의 구조

* code, data, heap, stack
* code: 컴파일된 소스코드가 저장되는 영역. 즉, 프로그램 자기 자신. 중간에 소스가 변경되지 않도록 read only로 저장됨
* data: 전역/static 변수가 할당되는 영역. java의 클래스 정보도 data 영역에 할당되는 것으로 아는데 정확하지 않음 (아닐수도 있음..)
* heap: 프로그래머가 할당/해제하는 메모리 영역. 동적으로 할당되는 메모리가 저장되는 영역이며 java의 경우 Garbage Collection이, c 같은 경우는 프로그래머가 직접 이 영역을 관리해주어야 한다.
* 함수/지역변수 등 '임시'적인 데이터가 저장되는 영역. 그 유명한 stack overflow가 이 stack을 말하는 것.

#### Uni Programming vs Multi Programming vs Multi Processing

* 유니프로그래밍과 멀티프로그래밍은 메모리 관점에서 정의하는 용어
* 멀티프로세싱은 CPU 관점에서 정의하는 용어
* 유니프로그래밍: 메모리에 단 하나의 프로세스만 올라갈 수 있다. (과거에는 메모리 크기가 작았기 때문에 단 하나의 프로세스만 메모리에 올려 사용했음.)
* 멀티프로그래밍: 메모리에 여러 개의 프로세스가 동시에 올라갈 수 있다. (현재는 대부분 이 방식 사용)
* 멀티프로세싱: CPU가 여러 개의 프로세스를 처리할 수 있다. (ex. 시분할)
* 현재는 대부분 멀티프로그래밍 + 멀티프로세싱 사용

#### 프로세스 제어 블록 (PCB, Process Control Block)

* 일종의 자료구조?로 '운영체제가 프로세스를 표현하는 방식'
* 프로세스의 정보를 담은 블록으로 운영체제는 PCB 내의 정보를 바탕으로 프로세스를 제어
* PCB들은 Linked List로 저장되며, 실행이 종료된 프로세스가 있다면 해당 PCB를 제거하고 Linked List를 최신화 함
* PCB의 구성: PCB 구조 포인터, 프로세스 상태, 프로세스 ID, 프로세스 카운터, 레지스터 정보, 메모리 관련 정보, CPU 스케줄링 정보 등

#### 프로세스의 상태 5가지: 생성(new), 준비(ready), 실행(run), 대기(wait), 완료(exit)

* 생성: PCB 생성. 메모리에 프로그램 적재를 요청
* 준비: CPU를 사용하기 위해 기다리는 상태
* 실행: CPU 스케줄러에 의해 프로세스가 실행되는 상태. 현재 실행 중인 프로세스는 CPU의 갯수만큼 존재하며 CPU 점유 시간이 초과되면 준비 상태로 복귀
* 대기: 프로세스가 입출력 요청을 하면 입출력 작업이 종료될 때까지 기다리게 됨. (입출력은 CPU의 속도에 비하면 매~우 느린 작업. CPU를 입출력 작업 동안 마냥 기다리게 할 수 없기 때문에 대기 상태가 있음) 입출력 작업이 모두 종료되면 준비 상태로 전환
* 완료: 프로세스가 종료되는 상태. PCB가 제거되고 메모리에서 프로세스가 소멸됨.

#### 컨텍스트 스위칭

* 프로세스 실행 중 다른 프로세스 실행을 위해 상태값을 저장하고 다른 프로세스를 시작하는 것
* 컨텍스트 스위칭이 발생하면 운영체제는 PCB에 프로세스 상태, 프로그램 카운터, 레지스터 값 등을 변경하여 최신화 함. (다시 작업할 때 처음부터 작업하지 않으려고 PCB에 현재까지의 작업내용을 적는 것이라고 생각하면 됨)

#### 쓰레드(Thread)

* 운영체제가 작업을 수행하는 것은 프로세스. But 프로세스를 많이 생성해 사용하는 건 메모리 측면에서 많은 비용이 드는 일이다. (프로세스를 만들 때마다 메모리 영역에서 PCB, code, data, heap, stack을 새로 할당해야 하기 때문)
* 쓰레드는 프로세스 내에서 해당 프로세스의 PCB, code, data, heap을 공유하며 실행되는 작업 단위. 쓰레드는 각각 고유한 stack을 지니는데, 메모리 관점에서 하나의 프로세스를 생성(새로운 PCB, code, data, heap, stack) 하는 것보다 하나의 쓰레드를 생성(새로운 stack, TCB)하는 것이 경제적이기 때문에 쓰레드가 사용된다.
* 운영체제는 쓰레드 생성 시 새로운 쓰레드 ID와 쓰레드 관리를 위한 쓰레드 제어 블록(TCB, Thread Control Block)을 생성한다.

#### 프로세스의 문제 발생 시 프로세스와 쓰레드: 안정성 vs 효율성

* 안정성 측면에서는 프로세스가 유리
* 효율성 측면에서는 쓰레드가 유리

안정성 측면: 각각의 프로세스는 독립적. 하나의 프로세스에 문제가 생겨도 다른 프로세스는 영향을 받지 않음.

효율성 측면: 프로세스 간의 통신에는 IPC 통신(Inter Process Communication)이 사용됨. IPC 통신은 비용이 크기 때문에 오버헤드가 크고 속도가 느림. 쓰레드는 한 프로세스 내에서 스택을 제외한 모든 자원을 공유하기 때문에 비용이 훨씬 저렴함.


#### CPU 스케줄링이란

어떤 프로세스에 CPU 리소스를 주어야 하는지 결정하는 작업. 컴퓨터 시스템의 효율에 직결되는 중요한 작업으로 운영체제를 공부할 때 가장 중요한 주제 중 하나이다. 


#### CPU 스케줄링의 고려사항

1. 어떤 프로세스에게 CPU 리소스를 주어야 하는가?
2. CPU를 할당 받은 프로세스가 얼마의 시간 동안 CPU를 사용해야 하는가?

-> 컴퓨터의 성능에 굉장히 많은 영향을 미침

#### CPU 스케줄링의 목표

1. 공평성: 가장 큰 목표로 모든 프로세스가 공평하게 CPU의 리소스를 사용할 수 있어야 함 (경우에 따라 공평의 기준은 다를 수 있음. 예를 들어 자율주행의 경우 탑승자의 안전을 위한 프로세스에게 더 많은 우선권을 주는 것이 공평함)
2. 리소스 사용률: CPU의 사용률을 높이거나 I/O 디바이스의 사용률을 높이는 것을 목표로 함
3. 오버헤드 최소화: 스케줄링을 위한 계산이 복잡하거나 과도하게 많은 컨텍스트 스위칭이 발생할 경우 스케줄링에 많은 비용이 발생할 수 있음. 배보다 배꼽이 커지는 꼴로, 이러한 오버헤드를 최소화하는 것을 목표로 함
4. 처리량: 같은 시간 내 더 많은 처리를 할 수 있는 것을 목표로 함
5. 대기시간: 작업을 요청하고 실제 작업이 이루어지기까지 대기하는 시간이 적은 것을 목표로 함
6. 응답시간: 대화형 시스템의 경우 사용자의 요청에 얼마나 빠르게 응답하는지가 중요하기 때문에 응답시간이 빠른 것을 목표로 함


#### CPU 스케줄링 알고리즘

CPU 스케줄링은 PCB의 상태 중 준비, 대기, 실행 상태와 관련이 있음. 그 중 준비와 대기 상태는 자료구조 중 QUEUE로 이루어져 있기 때문에 CPU 스케줄링 알고리즘은 기본적으로 선납선출의 성격을 띔.

* 단순한 Queue: FIFO(First In First Out) 즉, 스케줄링 큐에 들어오는 순서대로 CPU를 할당해 작업. 먼저 들어온 프로세스가 완전히 끝나야만 다음 프로세스가 실행될 수 있음. I/O 작업이 있거나 프로세스의 burst 시간에 따라 비효율적일 수 있음. (초기에 사용됨)
* SLF(Shortest Job First) 알고리즘: Queue의 단점 즉, burst 시간에 따른 대기 시간 차이가 심한 것을 해소하고자 도입됨. 원리는 가장 빨리 끝나는 프로세스를 먼저 실행하는 것. Queue보다 이론상 빠르지만 구현상 2가지 심각한 문제가 있음.
  * 어떤 프로세스가 언제 끝날지 알 수 없음 (ex. 인터넷을 켜놓고 사용하는 사용자가 인터넷을 언제 닫을지 알 수 없음)
  * burst 타임이 긴 프로세스가 언제 실행될지 알 수 없음 (중간에 계속 burst 타임이 짧은 프로세스가 유입될 경우 계속 순서가 밀림)
  * 이러한 이유로 SLF는 사용되지 않음.
* RR(Round Robin) 알고리즘: 시분할 방식. 일정 시간만큼만 프로세스에게 CPU 할당권을 주고 실행시간이 종료되면 프로세스를 강제 종료, 큐의 가장 뒤쪽으로 밀어 넣음.
* MLFQ(Multi Level Feedback Queue) 알고리즘: RR을 업그레이드한 알고리즘으로 오늘 날 운영체제에서 가장 일반적으로 사용되는 CPU 스케줄링 알고리즘. 프로세스를 CPU bound process와 I/O bound process로 나누어 각각에 다른 타임 슬라이스를 할당
  * 타임 슬라이스 = CPU를 사용할 수 있는 시간. 타임 슬라이스가 너무 길 경우 스택에서 발생하는 문제가 발생하고 너무 짧을 경우 스케줄링에 필요한 자원이 너무 많이 들어 오버헤드가 커짐 (적당해야 한다)

#### 공유자원과 임계구역

* 공유자원: 여러 프로세스가 공동으로 이용하는 변수, 메모리, 파일 등을 말함. 각 프로세스의 접근 순서에 따라 결과가 달라질 수 있음. 운영체제는 컨텍스트 스위칭을 통해 프로세스를 시분할 처리하기 때문에 공유자원을 사용하는 프로세스가 언제 어떻게 실행될지 예측하기 어려움
* 임계구역: 여러 프로세스가 동시에 사용하면 안되는 영역 즉, 공유자원에 대한 프로세스의 접근 순서에 따라 실행 결과가 달라질 수 있는 프로그램 영역을 말함.


#### 동기화 문제와 경쟁조건

* 동기화 문제: 공유자원을 여러 프로세스가 동시에 사용함으로써 발생하는 문제
* 경쟁 조건: 공유자원을 두개 이상의 프로세스가 동시에 사용하려고 할 때 발생하는 조건. 여러 프로세스가 동시에 공유자원에 접근하고자 할 때, 경쟁 조건이 발생했다고 말한다.

#### 교착 상태(데드락)

* 두 개 이상의 프로세스가 서로의 작업이 끝나기를 기다리고 있는 상황에서 무한정 대기상태에 빠지는 상태.
* 멀티 프로그래밍 환경에서 흔하게 발생할 수 있는 문제이지만 이 문제를 해결하는 일반적인 방법은 아직 없음.

#### 교착 상태의 조건

교착 상태의 조건에는 총 4가지가 있는데, 이 중 하나라도 충족되지 않으면 교착 상태는 발생하지 않음.

1. 상호배제: 어떤 프로세스가 한 리소스를 점유했다면 다른 프로세스는 그 리소스를 사용하면 안된다.
2. 비선점: 프로세스가 리소스를 사용할 때 다른 프로세스가 그 리소스를 빼앗으면 안된다.
3. 점유와 대기: 프로세스가 리소스 A를 얻은 상태에서 작업을 위해 리소스 B를 동시에 원하는 상태.
4. 원형 대기: 여러 프로세스가 서로 상대 프로세스의 자원을 기다리면서 자기 자신의 리소스를 놓지 않는 상태.

이론상 교착 상태는 위 조건 중 하나라도 충족되지 않으면 발생하지 않지만, 이를 바탕으로 교착상태를 예방하는 것은 비용이 매우 많이 들고 어렵다고 한다! -> 그래서 일반적으로 교착 상태를 발생시키지 않는 것에 초점을 두지 않고 교착 상태가 발생했을 때 어떻게 해결해야 하는지에 더 집중한다고 한다.
