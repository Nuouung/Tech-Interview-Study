# 공부


#### 프로그램과 프로세스

* 프로그램(Program): 하드디스크 등에 저장된 명령문의 집합체
* 프로세스(Process): 실행 중인 프로그램 (하드디스크에 있는 프로그램이 메모리에 올라가면 실행 중인 프로그램, 즉 프로세스가 된다!)


#### 프로세스의 구조

* code, data, heap, stack
* code: 컴파일된 소스코드가 저장되는 영역. 즉, 프로그램 자기 자신. 중간에 소스가 변경되지 않도록 read only로 저장됨
* data: 전역/static 변수가 할당되는 영역. java의 클래스 정보도 data 영역에 할당되는 것으로 아는데 정확하지 않음 (아닐수도 있음..)
* heap: 프로그래머가 할당/해제하는 메모리 영역. 동적으로 할당되는 메모리가 저장되는 영역이며 java의 경우 Garbage Collection이, c 같은 경우는 프로그래머가 직접 이 영역을 관리해주어야 한다.
* 함수/지역변수 등 '임시'적인 데이터가 저장되는 영역. 그 유명한 stack overflow가 이 stack을 말하는 것.

#### Uni Programming vs Multi Programming vs Multi Processing

* 유니프로그래밍과 멀티프로그래밍은 메모리 관점에서 정의하는 용어
* 멀티프로세싱은 CPU 관점에서 정의하는 용어
* 유니프로그래밍: 메모리에 단 하나의 프로세스만 올라갈 수 있다. (과거에는 메모리 크기가 작았기 때문에 단 하나의 프로세스만 메모리에 올려 사용했음.)
* 멀티프로그래밍: 메모리에 여러 개의 프로세스가 동시에 올라갈 수 있다. (현재는 대부분 이 방식 사용)
* 멀티프로세싱: CPU가 여러 개의 프로세스를 처리할 수 있다. (ex. 시분할)
* 현재는 대부분 멀티프로그래밍 + 멀티프로세싱 사용

#### 프로세스 제어 블록 (PCB, Process Control Block)

* 일종의 자료구조?로 '운영체제가 프로세스를 표현하는 방식'
* 프로세스의 정보를 담은 블록으로 운영체제는 PCB 내의 정보를 바탕으로 프로세스를 제어
* PCB들은 Linked List로 저장되며, 실행이 종료된 프로세스가 있다면 해당 PCB를 제거하고 Linked List를 최신화 함
* PCB의 구성: PCB 구조 포인터, 프로세스 상태, 프로세스 ID, 프로세스 카운터, 레지스터 정보, 메모리 관련 정보, CPU 스케줄링 정보 등

#### 프로세스의 상태 5가지: 생성(new), 준비(ready), 실행(run), 대기(wait), 완료(exit)

* 생성: PCB 생성. 메모리에 프로그램 적재를 요청
* 준비: CPU를 사용하기 위해 기다리는 상태
* 실행: CPU 스케줄러에 의해 프로세스가 실행되는 상태. 현재 실행 중인 프로세스는 CPU의 갯수만큼 존재하며 CPU 점유 시간이 초과되면 준비 상태로 복귀
* 대기: 프로세스가 입출력 요청을 하면 입출력 작업이 종료될 때까지 기다리게 됨. (입출력은 CPU의 속도에 비하면 매~우 느린 작업. CPU를 입출력 작업 동안 마냥 기다리게 할 수 없기 때문에 대기 상태가 있음) 입출력 작업이 모두 종료되면 준비 상태로 전환
* 완료: 프로세스가 종료되는 상태. PCB가 제거되고 메모리에서 프로세스가 소멸됨.

#### 컨텍스트 스위칭

* 프로세스 실행 중 다른 프로세스 실행을 위해 상태값을 저장하고 다른 프로세스를 시작하는 것
* 컨텍스트 스위칭이 발생하면 운영체제는 PCB에 프로세스 상태, 프로그램 카운터, 레지스터 값 등을 변경하여 최신화 함. (다시 작업할 때 처음부터 작업하지 않으려고 PCB에 현재까지의 작업내용을 적는 것이라고 생각하면 됨)

#### 쓰레드(Thread)

* 운영체제가 작업을 수행하는 것은 프로세스. But 프로세스를 많이 생성해 사용하는 건 메모리 측면에서 많은 비용이 드는 일이다. (프로세스를 만들 때마다 메모리 영역에서 PCB, code, data, heap, stack을 새로 할당해야 하기 때문)
* 쓰레드는 프로세스 내에서 해당 프로세스의 PCB, code, data, heap을 공유하며 실행되는 작업 단위. 쓰레드는 각각 고유한 stack을 지니는데, 메모리 관점에서 하나의 프로세스를 생성(새로운 PCB, code, data, heap, stack) 하는 것보다 하나의 쓰레드를 생성(새로운 stack, TCB)하는 것이 경제적이기 때문에 쓰레드가 사용된다.
* 운영체제는 쓰레드 생성 시 새로운 쓰레드 ID와 쓰레드 관리를 위한 쓰레드 제어 블록(TCB, Thread Control Block)을 생성한다.

#### 프로세스의 문제 발생 시 프로세스와 쓰레드: 안정성 vs 효율성

* 안정성 측면에서는 프로세스가 유리
* 효율성 측면에서는 쓰레드가 유리

안정성 측면: 각각의 프로세스는 독립적. 하나의 프로세스에 문제가 생겨도 다른 프로세스는 영향을 받지 않음.

효율성 측면: 프로세스 간의 통신에는 IPC 통신(Inter Process Communication)이 사용됨. IPC 통신은 비용이 크기 때문에 오버헤드가 크고 속도가 느림. 쓰레드는 한 프로세스 내에서 스택을 제외한 모든 자원을 공유하기 때문에 비용이 훨씬 저렴함.


#### CPU 스케줄링이란

어떤 프로세스에 CPU 리소스를 주어야 하는지 결정하는 작업. 컴퓨터 시스템의 효율에 직결되는 중요한 작업으로 운영체제를 공부할 때 가장 중요한 주제 중 하나이다. 


#### CPU 스케줄링의 고려사항

1. 어떤 프로세스에게 CPU 리소스를 주어야 하는가?
2. CPU를 할당 받은 프로세스가 얼마의 시간 동안 CPU를 사용해야 하는가?

-> 컴퓨터의 성능에 굉장히 많은 영향을 미침

#### CPU 스케줄링의 목표

1. 공평성: 가장 큰 목표로 모든 프로세스가 공평하게 CPU의 리소스를 사용할 수 있어야 함 (경우에 따라 공평의 기준은 다를 수 있음. 예를 들어 자율주행의 경우 탑승자의 안전을 위한 프로세스에게 더 많은 우선권을 주는 것이 공평함)
2. 리소스 사용률: CPU의 사용률을 높이거나 I/O 디바이스의 사용률을 높이는 것을 목표로 함
3. 오버헤드 최소화: 스케줄링을 위한 계산이 복잡하거나 과도하게 많은 컨텍스트 스위칭이 발생할 경우 스케줄링에 많은 비용이 발생할 수 있음. 배보다 배꼽이 커지는 꼴로, 이러한 오버헤드를 최소화하는 것을 목표로 함
4. 처리량: 같은 시간 내 더 많은 처리를 할 수 있는 것을 목표로 함
5. 대기시간: 작업을 요청하고 실제 작업이 이루어지기까지 대기하는 시간이 적은 것을 목표로 함
6. 응답시간: 대화형 시스템의 경우 사용자의 요청에 얼마나 빠르게 응답하는지가 중요하기 때문에 응답시간이 빠른 것을 목표로 함


#### CPU 스케줄링 알고리즘

CPU 스케줄링은 PCB의 상태 중 준비, 대기, 실행 상태와 관련이 있음. 그 중 준비와 대기 상태는 자료구조 중 QUEUE로 이루어져 있기 때문에 CPU 스케줄링 알고리즘은 기본적으로 선납선출의 성격을 띔.

* 단순한 Queue: FIFO(First In First Out) 즉, 스케줄링 큐에 들어오는 순서대로 CPU를 할당해 작업. 먼저 들어온 프로세스가 완전히 끝나야만 다음 프로세스가 실행될 수 있음. I/O 작업이 있거나 프로세스의 burst 시간에 따라 비효율적일 수 있음. (초기에 사용됨)
* SLF(Shortest Job First) 알고리즘: Queue의 단점 즉, burst 시간에 따른 대기 시간 차이가 심한 것을 해소하고자 도입됨. 원리는 가장 빨리 끝나는 프로세스를 먼저 실행하는 것. Queue보다 이론상 빠르지만 구현상 2가지 심각한 문제가 있음.
  * 어떤 프로세스가 언제 끝날지 알 수 없음 (ex. 인터넷을 켜놓고 사용하는 사용자가 인터넷을 언제 닫을지 알 수 없음)
  * burst 타임이 긴 프로세스가 언제 실행될지 알 수 없음 (중간에 계속 burst 타임이 짧은 프로세스가 유입될 경우 계속 순서가 밀림)
  * 이러한 이유로 SLF는 사용되지 않음.
* RR(Round Robin) 알고리즘: 시분할 방식. 일정 시간만큼만 프로세스에게 CPU 할당권을 주고 실행시간이 종료되면 프로세스를 강제 종료, 큐의 가장 뒤쪽으로 밀어 넣음.
* MLFQ(Multi Level Feedback Queue) 알고리즘: RR을 업그레이드한 알고리즘으로 오늘 날 운영체제에서 가장 일반적으로 사용되는 CPU 스케줄링 알고리즘. 프로세스를 CPU bound process와 I/O bound process로 나누어 각각에 다른 타임 슬라이스를 할당
  * 타임 슬라이스 = CPU를 사용할 수 있는 시간. 타임 슬라이스가 너무 길 경우 스택에서 발생하는 문제가 발생하고 너무 짧을 경우 스케줄링에 필요한 자원이 너무 많이 들어 오버헤드가 커짐 (적당해야 한다)

#### 공유자원과 임계구역

* 공유자원: 여러 프로세스가 공동으로 이용하는 변수, 메모리, 파일 등을 말함. 각 프로세스의 접근 순서에 따라 결과가 달라질 수 있음. 운영체제는 컨텍스트 스위칭을 통해 프로세스를 시분할 처리하기 때문에 공유자원을 사용하는 프로세스가 언제 어떻게 실행될지 예측하기 어려움
* 임계구역: 여러 프로세스가 동시에 사용하면 안되는 영역 즉, 공유자원에 대한 프로세스의 접근 순서에 따라 실행 결과가 달라질 수 있는 프로그램 영역을 말함.


#### 동기화 문제와 경쟁조건

* 동기화 문제: 공유자원을 여러 프로세스가 동시에 사용함으로써 발생하는 문제
* 경쟁 조건: 공유자원을 두개 이상의 프로세스가 동시에 사용하려고 할 때 발생하는 조건. 여러 프로세스가 동시에 공유자원에 접근하고자 할 때, 경쟁 조건이 발생했다고 말한다.

#### 교착 상태(데드락)

* 두 개 이상의 프로세스가 서로의 작업이 끝나기를 기다리고 있는 상황에서 무한정 대기상태에 빠지는 상태.
* 멀티 프로그래밍 환경에서 흔하게 발생할 수 있는 문제이지만 이 문제를 해결하는 일반적인 방법은 아직 없음.

#### 교착 상태의 조건

교착 상태의 조건에는 총 4가지가 있는데, 이 중 하나라도 충족되지 않으면 교착 상태는 발생하지 않음.

1. 상호배제: 어떤 프로세스가 한 리소스를 점유했다면 다른 프로세스는 그 리소스를 사용하면 안된다.
2. 비선점: 프로세스가 리소스를 사용할 때 다른 프로세스가 그 리소스를 빼앗으면 안된다.
3. 점유와 대기: 프로세스가 리소스 A를 얻은 상태에서 작업을 위해 리소스 B를 동시에 원하는 상태.
4. 원형 대기: 여러 프로세스가 서로 상대 프로세스의 자원을 기다리면서 자기 자신의 리소스를 놓지 않는 상태.

이론상 교착 상태는 위 조건 중 하나라도 충족되지 않으면 발생하지 않지만, 이를 바탕으로 교착상태를 예방하는 것은 비용이 매우 많이 들고 어렵다고 한다! -> 그래서 일반적으로 교착 상태를 발생시키지 않는 것에 초점을 두지 않고 교착 상태가 발생했을 때 어떻게 해결해야 하는지에 더 집중한다고 한다.

#### 메모리의 종류

* CPU 내부 - 레지스터, 캐시
* 메인 메모리(RAM)
* 보조 저장 장치 - HDD, SSD
* 특징: CPU에 있는 메모리는 매우 빠르지만, 용량이 작고 매우 비싸다
* 특징: 메인 메모리는 흔히 그냥 '메모리'라 불린다. 폰 노이만 구조의 컴퓨터는 모든 프로그램을 메인 메모리에 올려 작동시킨다.
* 특징: 보조 저장 장치는 컴퓨터에 전원이 공급되지 않을 때도 데이터의 유실이 없는 저장 장치로 상대적으로 가격이 저렴하고 용량이 크지만 속도가 느리다.
 

#### 왜 메모리는 여러 종류가 있을까?

*경제성, 채산성, 효율성 때문이다.
* CPU 내부에 필요한 메모리는 매우 빠른 속도가 요구된다. 반면 보조 저장 장치로 쓰이는 메모리는 많은 용량이 필요하다.
* HDD, SSD와 같이 보조 저장 장치에 쓰이는 메모리는 가격이 싼 대신 용량이 크다. 반면 레지스터와 캐시는 가격이 비싼 대신 속도가 매우 빠르다.
* 컴퓨터 내부, 각 장치에 요구되는 메모리의 역할과 필요가 다르기 때문에, 무엇보다 레지스터, 캐시, 메인 메모리 등은 비싸기 때문에 메모리는 여러 종류가 있다.
* (HDD, SSD 같은 비교적 싼 메모리를 저장 장치로 사용하는 대신 레지스터와 캐시를 보조 저장 장치로 사용하려고 한다면 컴퓨터의 가격이 천문학적으로 올라갈 것이다.)
 

#### 각각의 메모리는 어떤 역할?

* 레지스터: CPU 내에 존재하는 레지스터는 CPU에서의 각종 연산 값을 저장하는 메모리이다. 32bit와 64bit가 존재하며 CPU가 32비트 CPU인지 64비트 CPU인지를 결정하는 메모리이다. 
* 캐시: CPU 내에서 레지스터와 메인 메모리 사이에 위치하는 캐시는 레지스터에 사용될 데이터의 값을 저장하는데 쓰인다. 레지스터는 매우 빠르고, 메인 메모리는 레지스터에 비해 상대적으로 느리기 때문에 레지스터의 작업 효율성을 위해 캐시가 존재한다. L1, L2, L3 등의 캐시가 존재하며 레지스터가 수행해야 할 과업의 우선순위가 높을수록 낮은 수치의 캐시에 데이터가 저장된다.
* 메인 메모리: 운영체제와 컴퓨터에 사용되는 모든 프로세스가 올라가는 공간이다. 폰 노이만 구조의 컴퓨터에는 반드시 필요한 핵심적인 역할을 한다. CPU는 작업을 할 때 메인 메모리에 있는 프로세스를 가져와 작업을 수행한다.
* 보조 저장 장치: 다른 모든 종류의 메모리는 컴퓨터의 전원이 중단될 경우 데이터가 유실되는 휘발성 메모리이지만 보조 저장 장치는 비휘발성 메모리이다. 운영체제를 포함한 프로그램들의 정보를 저장한다.
 

#### 메모리와 주소

* 메모리(메인 메모리)에 단 하나의 프로세스만이 올라갈 수 있는 유니프로그래밍 방식에서는 메모리를 관리할 필요성이 적다.
* 그러나 오늘날의 컴퓨터는 메모리에 다수의 프로세스를 동시에 올려 사용하는 멀티프로그래밍 방식을 사용하기 때문에 메모리 위에 있는 프로세스들의 위치를 파악하고 메모리를 관리하는 것이 매우 중요하다.
* 이를 위해 운영체제는 메모리를 1byte의 크기로 쪼개 각각의 크기를 구역으로 나누어 숫자로 매겨 관리한다.
* 이를 '메모리 주소'라고 한다.
* 메모리 주소는 0x0부터 시작해 0x1000, 0x6400 이런 식으로 올라간다.
* 메모리의 주소는 크게 물리 주소와 논리 주소로 나눌 수 있다.
 

#### 물리 주소와 논리 주소

* 물리 주소: 메모리 관리자(Memory Management Unit)가 바라보는 메모리 주소. 0x0번지부터 시작하는 주소 공간을 말한다. (실제 주소값)
* 논리 주소: 사용자 및 프로세스가 바라보는 주소 공간이다. 모든 프로세스는 자신의 위치를 0x0번지로 가정하고 작동하는데 이 때의 주소를 논리 주소라고 한다. 프로세스의 논리 주소는 MMU(메모리 관리자)에 의해 물리 주소로 변환되어 사용된다.
 

##### 운영체제와 메모리 주소

* 운영체제는 소프트웨어 중 유일하게 하드웨어를 조작할 수 있는 소프트웨어이기 때문에 매우 특별한 종류의 프로그램이다.
* 운영체제는 컴퓨터의 작동에 매우 중요한 역할을 하기 때문에 메모리에는 운영체제를 위한 공간이 따로 존재한다.
* 메모리는 운영체제 공간과 사용자 공간을 나누어 운영체제가 올라가는 위치와 다른 프로세스가 올라가는 위치를 구별한다.
* 운영체제 공간과 사용자 공간 사이에는 하드웨어적으로 양 공간을 나누는 경계 레지스터가 존재한다.
* 만약, 악의적인 의도를 갖춘 사용자에 의해 사용자 공간의 프로세스가 운영체제 공간을 침범하려 할 경우 메모리 관리자에 의해 강제적으로 종료된다. (메모리 관리자는 사용자 프로세스가 사용자 공간을 벗어나는지 검사한다. 벗어나면, 프로세스를 종료시킨다.)
 

#### 메모리가 프로세스에게 주소를 할당하는 방식

* 가변 분할 방식: 메모리에 올라오는 프로세스의 크기에 비례해 메모리의 크기를 할당하는 방식. 프로세스가 크면 메모리를 많이 할당하고, 프로세스가 작으면 메모리를 적게 할당한다.
* 고정 분할 방식: 프로세스의 크기에 상관 없이 미리 '정해진' 메모리 크기를 할당하는 방식. 정해진 메모리 크기로 프로세스를 할당하기 때문에 프로세스의 크기가 메모리 할당량을 초과할 경우 프로세스를 잘게 잘라 메모리 상에 분산해 배치시킨다.
 

#### 가변 분할 방식의 장점과 단점

* 가변 분할 방식은 한 프로세스가 메모리의 연속된 공간에 할당된다. 가변 분할 방식은 이러한 이유로 '연속 메모리 할당'이라고도 칭해진다.
* 장점: 메모리가 프로세스의 크기보다 더 많이 할당되는 '내부 단편화'가 발생하지 않는다.
* 단점: 외부 단편화가 발생하기 때문에 주기적으로 조각난 메모리 공간을 합치는 조각모음을 해야 한다. 이에 따른 오버헤드가 크다. (실행 중인 프로세스를 종료해야 하고, 조각모음을 하면서 프로세스를 이동해야 하기 때문)
* 외부 단편화의 예) 50mb와 10mb 두 프로세스가 나갔다고 해보자 <- 연속된 공간이 아니었을 경우 총 메모리 가용량은 60mb이지만 실제로는 50mb 공간 10mb 공간으로 나뉨 <- 60mb의 프로세스가 메모리에 올라가고자 할 때 올라갈 수가 없음
 

#### 고정 분할 방식의 장점과 단점

* 고정 분할 방식은 한 프로세스가 메모리상에 분산되어 할당된다. 고정 분할 방식은 이러한 성격 때문에 '비연속 메모리 할당'이라고도 칭해진다.
* 장점: 구현이 쉽다. 외부 단편화가 발생하기 않기 때문에 오버헤드가 적다.
* 단점: 프로세스의 크기보다 큰 메모리를 할당하는 내부 단편화가 발생한다.
* 가변 분할 방식과 고정 분할 방식의 장점과 단점으로 오늘날의 운영체제는 가변과 고정 분할 방식을 혼합해 사용한다.


#### 가상메모리

* "RAM은 결코 충분하지 않다,"라는 고민에서 시작된 기법으로 물리 메모리 크기의 한계를 극복하기 위해 나온 기술임
* 컴퓨터에 실제로 가용한 메모리를 추상화하여 사용자들에게 하여금 매우 큰 메모리로 보이게 만드는 기법
* 가상메모리의 핵심은 프로세스를 메모리에 올릴 때 프로세스 전체를 메모리에 올리는 것이 아니라 필요한 부분만 쪼개 메모리에 올리는 것
* 프로세스는 실행될 때 실행에 필요한 일부분만 메모리에 올라가고 나머지는 하드디스크의 스왑 영역에 위치하게 됨
* 가상 메모리 시스템을 구현하기 위해서는 MMU(Memory Management Unit, 메모리 관리자)라고 불리는 특수한 메모리 관리 하드웨어가 필요하며(과거에는 MMU가 별도의 하드웨어였지만 최근의 아키텍처에서는 프로세서와 같은 칩에 회로로 삽입된다고 한다) MMU는 메모리 상의 가상주소를 물리주소로 변환하고 메모리를 보호하는 기능을 수행함
* MMU는 가상주소와 물리주소를 일대일 매핑 테이블로 관리해 잘게 쪼개진 프로세스를 관리함
* MMU는 가상메모리를 위한 메모리를 일정한 비율로 나누어 각각의 프로세스에게 할당하는데 이 때 메모리를 나누는 방법은 메모리가 프로세스에게 주소를 할당하는 방식과 같은 가변 분할 방식과 고정 분할 방식으로 나뉨
 * 가변 분할 방식(세그멘테이션)
 * 고정 분할 방식(페이징)
* 세그멘테이션에는 '외부 단편화', 페이징에는 '내부 단편화'의 문제가 있기 때문에 각각의 단점을 보완한 세그멘테이션-페이징 혼용 기법을 사용하기도 함
* 세그멘테이션-페이징 혼용 기법
 

#### 세그멘테이션 (배치정책)

* 세그멘테이션에서의 프로세스는 함수나 모듈 등의 세그먼트 집합으로 여겨짐 (메인코드, 전역데이터, 힙, 라이브러리, 스택 등을 세그먼트라는 단위로 나누어 프로세스를 바라봄)
* 각각의 세그먼트는 역할(함수, 모듈 등)의 단위로 나누어지기 때문에 크기가 일정하지 않음 (cf. 페이징은 일정한 크기에 따라 프로세스를 나누기 때문에 크기가 일정)
* MMU는 세그멘테이션 테이블을 가지고 있어 이를 토대로 가상메모리 상의 논리 주소를 물리 주소로 변환함
 

#### 세그멘테이션의 물리 주소 변환 과정

* 세그멘테이션 테이블에는 Base Address와 Bound Address 정보가 저장됨 (index = 세그먼트 번호 / value = Base Address, Bound Address)
* Bass Address: 세그먼트 시작 주소
* Bound Address: 세그먼트의 크기

1. CPU에서 논리 주소를 전달 (CPU: 논리 주소 0x123번지의 물리 메모리 주소 알려줘!)
2. MMU 논리 주소가 몇번 세그먼트인지 판별 (MMU: 세그먼트 3번이군!)
3. MMU 내의 Segment Table Base Register를 이용, 물리 메모리 내의 세그멘테이션 테이블을 찾음 (MMU: 물리메모리 n번지에 있는 세그멘테이션 테이블 가져 와야지!)
4. 세그먼트 번호를 index로 하는 Base Address와 Bound Address를 찾음 (MMU: 세그먼트 3번이니 3번 index 참조! Base Address는 6400, Bound Address는 500이군!)
5. CPU에서 가져온 논리 주소와 Bound Address의 크기를 비교 (MMU: 123과 500 크기 비교!)
6. 만약 논리 주소가 Bound Address보다 작다면 논리 주소와 Bass Address를 더해 물리 주소를 계산 (MMU: 123 < 500이니 논리 주소와 Bass Address를 더하자! 123 + 6400 = 6523!)
7. 만약 논리 주소가 Bound Address보다 크다면 메모리를 침범했다고 여기고 에러를 발생 (MMU: 메모리 침범! 에러!)
 

#### 세그멘테이션의 장점

* 메모리를 가변적으로 분할할 수 있음
* 각각의 영역을 모듈로 처리할 수 있어 공유와 각 영역에 대한 메모리 접근 보호가 편리함 (관리가 쉬움)
 

#### 세그멘테이션의 단점

* 가변 분할 방식의 단점인 '외부 단편화'가 발생
 

#### 페이징 (배치정책)

* 세그멘테이션의 외부단편화를 개선시키기 위해 고안
* 메모리 할당 시 정해진 크기만큼 나누어 관리하기 때문에 외부 단편화가 발생하지 않음
* 세그멘테이션은 세그먼트(작업단위? 논리적인 연관성을 가진 집합체?)의 크기별로 메모리를 나누어 할당하는 방식, 페이징은 메모리를 일정한 크기만큼 나누어 할당하는 방식
 

#### 페이지와 프레임

* 페이지: 논리주소공간에서 일정한 비율로 나눈 메모리의 단위
* 프레임: 물리주소공간에서 일정한 비율로 나눈 메모리의 단위
* 논리주소공간에서는 페이지, 물리주소공간에서는 프레임이라고 부른다.
 

#### 세그멘테이션의 물리 주소 변환 과정

* MMU는 페이지 테이블을 가짐
* key: 페이지
* value: 프레임

1. CPU에서 논리 주소를 전달 (CPU: 논리 주소 0x0번지의 물리 메모리 주소 알려줘!)
2. MMU는 논리주소가 몇번 페이지인지, 오프셋이 얼마인지 판별 (MMU: 논리주소 0x0번지는 페이지 0이고 오프셋은 0이군!)
3. 페이지 넘버 = 논리 주소 / 페이지 크기
4. 오프셋 = 논리 주소 % 페이지 크기
5. MMU 내의 PTBR(Page Table Base Register)을 이용, 물리 메모리 내의 페이지 테이블을 조회함
6. 페이지 번호를 인덱스로 프레임 번호를 조회 (MMU: 페이지 0이면 프레임 3번이네!)
7. 오프셋을 이용해 물리주소로 변환 (MMU: 3번 프레임에 오프셋 0을 더하니 3!)
 

#### 페이징의 장점

* 외부단편화가 발생하지 않음
 

#### 페이징의 단점

* 내부단편화가 발생 <- 그러나 세그멘테이션의 외부단편화만큼 많은 단편화가 발생하지 않기 때문에 세그멘테이션보다 페이징 기법을 많이 사용한다고 함
* 세그멘테이션처럼 논리적인 단위로 크기가 나뉘지 않기 때문에 공유와 각 메모리에 대한 접근 보호가 어려움. 페이징의 크기를 얼마나 할 것이냐가 페이징에서는 매우 중요한 이슈
